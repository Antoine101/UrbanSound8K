{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8643156f",
   "metadata": {},
   "source": [
    "# <center>UrbanSound8K - Features Sensitivity to Processing Parameters</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d24179f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Libraries-Import\" data-toc-modified-id=\"Libraries-Import-1\">Libraries Import</a></span></li><li><span><a href=\"#Paths\" data-toc-modified-id=\"Paths-2\">Paths</a></span></li><li><span><a href=\"#Import-of-the-Metadata-File\" data-toc-modified-id=\"Import-of-the-Metadata-File-3\">Import of the Metadata File</a></span></li><li><span><a href=\"#Choice-of-an-Event\" data-toc-modified-id=\"Choice-of-an-Event-4\">Choice of an Event</a></span></li><li><span><a href=\"#Audio-Processing-Parameters\" data-toc-modified-id=\"Audio-Processing-Parameters-5\">Audio Processing Parameters</a></span></li><li><span><a href=\"#Audio-Pre-Processing\" data-toc-modified-id=\"Audio-Pre-Processing-6\">Audio Pre-Processing</a></span></li><li><span><a href=\"#Spectrogram\" data-toc-modified-id=\"Spectrogram-7\">Spectrogram</a></span><ul class=\"toc-item\"><li><span><a href=\"#FFT-Size\" data-toc-modified-id=\"FFT-Size-7.1\">FFT Size</a></span></li><li><span><a href=\"#Hop-Length\" data-toc-modified-id=\"Hop-Length-7.2\">Hop Length</a></span></li><li><span><a href=\"#Windowing-Function\" data-toc-modified-id=\"Windowing-Function-7.3\">Windowing Function</a></span></li></ul></li><li><span><a href=\"#Mel-Spectrogram\" data-toc-modified-id=\"Mel-Spectrogram-8\">Mel-Spectrogram</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-Mel-Filterbanks\" data-toc-modified-id=\"Number-of-Mel-Filterbanks-8.1\">Number of Mel Filterbanks</a></span></li></ul></li><li><span><a href=\"#MFCC\" data-toc-modified-id=\"MFCC-9\">MFCC</a></span><ul class=\"toc-item\"><li><span><a href=\"#Number-of-Coefficients\" data-toc-modified-id=\"Number-of-Coefficients-9.1\">Number of Coefficients</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b501b",
   "metadata": {},
   "source": [
    "## Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b2e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import collections\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import IPython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b998fb",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452cd55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../dataset\"\n",
    "figures_path = \"../figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89814a62",
   "metadata": {},
   "source": [
    "## Import of the Metadata File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(dataset_path, \"UrbanSound8K.csv\"))\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39942466",
   "metadata": {},
   "source": [
    "## Choice of an Event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086c502",
   "metadata": {},
   "source": [
    "For a recall, the different classes present in the UrbanSound8K dataset are:\n",
    "- air_conditioner\n",
    "- car_horn\n",
    "- children_playing\n",
    "- dog_bark\n",
    "- drilling\n",
    "- engine_idling\n",
    "- gun_shot\n",
    "- jackhammer\n",
    "- siren\n",
    "- street_music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2a7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = metadata[\n",
    "    (metadata[\"class\"] == \"siren\") & \n",
    "    (metadata[\"salience\"] == 1) &\n",
    "    ((metadata[\"end\"] - metadata[\"start\"]) == 4)\n",
    "].sample(1)\n",
    "display(event)\n",
    "\n",
    "event_name = event[\"slice_file_name\"].item()\n",
    "event_fold = event[\"fold\"].item()\n",
    "event_class = event[\"class\"].item()\n",
    "event_path = os.path.join(dataset_path, f\"fold{event_fold}\", event_name)\n",
    "\n",
    "display(IPython.display.Audio(filename=event_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55a5bc",
   "metadata": {},
   "source": [
    "## Audio Processing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ccd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_length = 4\n",
    "target_sample_rate = 22050\n",
    "n_samples = target_length * target_sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e4260",
   "metadata": {},
   "source": [
    "## Audio Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd09269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio signal\n",
    "signal, sr = torchaudio.load(event_path)\n",
    "# Mix it down to mono if necessary\n",
    "if signal.shape[0] > 1:\n",
    "    signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "# Resample it\n",
    "resample_transform = transforms.Resample(sr, target_sample_rate)\n",
    "signal = resample_transform(signal)\n",
    "# Cut if necessary\n",
    "if signal.shape[1] > n_samples:\n",
    "    signal = signal[:, :n_samples]\n",
    "# Right pad if necessary\n",
    "if signal.shape[1] < n_samples:\n",
    "    n_missing_samples = n_samples - signal.shape[1]\n",
    "    last_dim_padding = (0, n_missing_samples)\n",
    "    signal = nn.functional.pad(signal, last_dim_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930abd6",
   "metadata": {},
   "source": [
    "## Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1aba86",
   "metadata": {},
   "source": [
    "### FFT Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_to_db_transform = torchaudio.transforms.AmplitudeToDB(\n",
    "                    # Scale of input tensor (\"power\" or \"magnitude\"). The power being the elementwise square of the magnitude. (Default: \"power\")\n",
    "                    stype = \"power\",\n",
    "                    # Minimum negative cut-off in decibels. A reasonable number is 80. (Default: None)\n",
    "                    top_db = None\n",
    "                    )\n",
    "\n",
    "n_fft_values = [128, 256, 512, 1024]\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(n_fft_values)/n_cols)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for index, n_fft_value in enumerate(n_fft_values):\n",
    "    \n",
    "        spectrogram_transform = torchaudio.transforms.Spectrogram( \n",
    "                    # Size of FFT, creates n_fft // 2 + 1 bins. (Default: 400)\n",
    "                    n_fft = n_fft_value,\n",
    "                    # Window size. (Default: n_fft)\n",
    "                    win_length = n_fft_value,\n",
    "                    # Length of hop between STFT windows. (Default: win_length // 2)\n",
    "                    hop_length = n_fft_value // 2,\n",
    "                    # Two sided padding of signal. (Default: 0)\n",
    "                    pad = 0,\n",
    "                    # A function to create a window tensor that is applied/multiplied to each frame/window. (Default: torch.hann_window)\n",
    "                    window_fn = torch.hann_window,\n",
    "                    # Exponent for the magnitude spectrogram, (must be > 0) e.g., 1 for energy, 2 for power, etc. (Default: 2)\n",
    "                    power = 2,\n",
    "                    # Whether to normalize by magnitude after stft. (Default: False)\n",
    "                    normalized = True,\n",
    "                    # Arguments for window function. (Default: None)\n",
    "                    wkwargs = None,\n",
    "                    # Whether to pad waveform on both sides so that the t-th frame is centered at time t x hop_length (Default: True)\n",
    "                    center = False,\n",
    "                    # Controls the padding method used when center is True. (Default: \"reflect\")\n",
    "                    pad_mode = \"reflect\",\n",
    "                    # Controls whether to return half of results to avoid redundancy. (Default: True)\n",
    "                    onesided = True,\n",
    "                    # Indicates whether the resulting complex-valued Tensor should be represented with native complex dtype, \n",
    "                    # such as torch.cfloat and torch.cdouble, or real dtype mimicking complex value with an extra dimension \n",
    "                    # for real and imaginary parts. (See also torch.view_as_real.)\n",
    "                    # This argument is only effective when power=None. It is ignored for cases where power is a number as in those cases, the returned tensor is power spectrogram, which is a real-valued tensor.\n",
    "                    return_complex = False\n",
    "                    )   \n",
    "        \n",
    "        num_channels, num_frames = signal.shape\n",
    "        time_axis = torch.arange(0, num_frames) / target_sample_rate\n",
    "    \n",
    "        spectrogram = spectrogram_transform(signal)\n",
    "        \n",
    "        spectrogram = torch.squeeze(spectrogram)\n",
    "        spectrogram_db = amplitude_to_db_transform(spectrogram)\n",
    "    \n",
    "        n_fft_spec = (spectrogram_db.shape[0] - 1) * 2\n",
    "        frequency = (target_sample_rate / n_fft_spec) * np.linspace(0, n_fft_spec/2, spectrogram_db.shape[0])\n",
    "    \n",
    "        ax = fig.add_subplot(n_rows, n_cols, index+1)\n",
    "        ax.imshow(spectrogram_db, extent=[0, target_length, 0, target_sample_rate/2], origin=\"lower\", aspect=\"auto\")\n",
    "        ax.set_title(f\"n_fft = {n_fft_value}\", fontweight=\"bold\", fontsize=12)\n",
    "        ax.set_ylabel(\"Frequency (Hz)\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        \n",
    "        \n",
    "fig.suptitle(f\"Spectrogram - {event_name} - Class : {event_class}\", fontsize=20, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "figure_name = f\"Analyse des Features - Spectrogramme - Sensibilité au Paramètre n_fft - {event_name} - {event_class}.png\"\n",
    "plt.savefig(os.path.join(figures_path, figure_name), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e156f10",
   "metadata": {},
   "source": [
    "### Hop Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_to_db_transform = torchaudio.transforms.AmplitudeToDB(\n",
    "                    # Scale of input tensor (\"power\" or \"magnitude\"). The power being the elementwise square of the magnitude. (Default: \"power\")\n",
    "                    stype = \"power\",\n",
    "                    # Minimum negative cut-off in decibels. A reasonable number is 80. (Default: None)\n",
    "                    top_db = None\n",
    "                    )\n",
    "\n",
    "hop_length_denominators = [8, 4, 2, 1]\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(hop_length_denominators)/n_cols)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for index, hop_length_denominator in enumerate(hop_length_denominators):\n",
    "    \n",
    "        spectrogram_transform = torchaudio.transforms.Spectrogram( \n",
    "                    # Size of FFT, creates n_fft // 2 + 1 bins. (Default: 400)\n",
    "                    n_fft = 1024,\n",
    "                    # Window size. (Default: n_fft)\n",
    "                    win_length = 1024,\n",
    "                    # Length of hop between STFT windows. (Default: win_length // 2)\n",
    "                    hop_length = 1024 // hop_length_denominator,\n",
    "                    # Two sided padding of signal. (Default: 0)\n",
    "                    pad = 0,\n",
    "                    # A function to create a window tensor that is applied/multiplied to each frame/window. (Default: torch.hann_window)\n",
    "                    window_fn = torch.hann_window,\n",
    "                    # Exponent for the magnitude spectrogram, (must be > 0) e.g., 1 for energy, 2 for power, etc. (Default: 2)\n",
    "                    power = 2,\n",
    "                    # Whether to normalize by magnitude after stft. (Default: False)\n",
    "                    normalized = True,\n",
    "                    # Arguments for window function. (Default: None)\n",
    "                    wkwargs = None,\n",
    "                    # Whether to pad waveform on both sides so that the t-th frame is centered at time t x hop_length (Default: True)\n",
    "                    center = False,\n",
    "                    # Controls the padding method used when center is True. (Default: \"reflect\")\n",
    "                    pad_mode = \"reflect\",\n",
    "                    # Controls whether to return half of results to avoid redundancy. (Default: True)\n",
    "                    onesided = True,\n",
    "                    # Indicates whether the resulting complex-valued Tensor should be represented with native complex dtype, \n",
    "                    # such as torch.cfloat and torch.cdouble, or real dtype mimicking complex value with an extra dimension \n",
    "                    # for real and imaginary parts. (See also torch.view_as_real.)\n",
    "                    # This argument is only effective when power=None. It is ignored for cases where power is a number as in those cases, the returned tensor is power spectrogram, which is a real-valued tensor.\n",
    "                    return_complex = False\n",
    "                    )   \n",
    "        \n",
    "        num_channels, num_frames = signal.shape\n",
    "        time_axis = torch.arange(0, num_frames) / target_sample_rate\n",
    "    \n",
    "        spectrogram = spectrogram_transform(signal)\n",
    "        spectrogram = torch.squeeze(spectrogram)\n",
    "        spectrogram_db = amplitude_to_db_transform(spectrogram)\n",
    "    \n",
    "        n_fft_spec = (spectrogram_db.shape[0] - 1) * 2\n",
    "        frequency = (target_sample_rate / n_fft_spec) * np.linspace(0, n_fft_spec/2, spectrogram_db.shape[0])\n",
    "    \n",
    "        ax = fig.add_subplot(n_rows, n_cols, index+1)\n",
    "        ax.imshow(spectrogram_db, extent=[0, target_length, 0, target_sample_rate/2], origin=\"lower\", aspect=\"auto\")\n",
    "        ax.set_title(f\"hop_length = n_fft/{hop_length_denominator}\", fontweight=\"bold\", fontsize=12)\n",
    "        ax.set_ylabel(\"Frequency (Hz)\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        \n",
    "\n",
    "fig.suptitle(f\"Spectrogram - {event_name} - Class : {event_class}\", fontsize=20, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "figure_name = f\"Analyse des Features - Spectrogramme - Sensibilité au Paramètre hop_length - {event_name} - {event_class}.png\"\n",
    "plt.savefig(os.path.join(figures_path, figure_name), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ccab98",
   "metadata": {},
   "source": [
    "### Windowing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_to_db_transform = torchaudio.transforms.AmplitudeToDB(\n",
    "                    # Scale of input tensor (\"power\" or \"magnitude\"). The power being the elementwise square of the magnitude. (Default: \"power\")\n",
    "                    stype = \"power\",\n",
    "                    # Minimum negative cut-off in decibels. A reasonable number is 80. (Default: None)\n",
    "                    top_db = None\n",
    "                    )\n",
    "\n",
    "window_functions = [\n",
    "    (\"Hann\", torch.hann_window), \n",
    "    (\"Hamming\", torch.hamming_window), \n",
    "    (\"Bartlett\", torch.bartlett_window), \n",
    "    (\"Blackman\", torch.blackman_window), \n",
    "    (\"Kaiser\", torch.kaiser_window)\n",
    "]\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(window_functions)/n_cols)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for index, (window_name, window_function) in enumerate(window_functions):\n",
    "    \n",
    "        spectrogram_transform = torchaudio.transforms.Spectrogram( \n",
    "                    # Size of FFT, creates n_fft // 2 + 1 bins. (Default: 400)\n",
    "                    n_fft = 1024,\n",
    "                    # Window size. (Default: n_fft)\n",
    "                    win_length = 1024,\n",
    "                    # Length of hop between STFT windows. (Default: win_length // 2)\n",
    "                    hop_length = 1024 // 2,\n",
    "                    # Two sided padding of signal. (Default: 0)\n",
    "                    pad = 0,\n",
    "                    # A function to create a window tensor that is applied/multiplied to each frame/window. (Default: torch.hann_window)\n",
    "                    window_fn = window_function,\n",
    "                    # Exponent for the magnitude spectrogram, (must be > 0) e.g., 1 for energy, 2 for power, etc. (Default: 2)\n",
    "                    power = 2,\n",
    "                    # Whether to normalize by magnitude after stft. (Default: False)\n",
    "                    normalized = True,\n",
    "                    # Arguments for window function. (Default: None)\n",
    "                    wkwargs = None,\n",
    "                    # Whether to pad waveform on both sides so that the t-th frame is centered at time t x hop_length (Default: True)\n",
    "                    center = False,\n",
    "                    # Controls the padding method used when center is True. (Default: \"reflect\")\n",
    "                    pad_mode = \"reflect\",\n",
    "                    # Controls whether to return half of results to avoid redundancy. (Default: True)\n",
    "                    onesided = True,\n",
    "                    # Indicates whether the resulting complex-valued Tensor should be represented with native complex dtype, \n",
    "                    # such as torch.cfloat and torch.cdouble, or real dtype mimicking complex value with an extra dimension \n",
    "                    # for real and imaginary parts. (See also torch.view_as_real.)\n",
    "                    # This argument is only effective when power=None. It is ignored for cases where power is a number as in those cases, the returned tensor is power spectrogram, which is a real-valued tensor.\n",
    "                    return_complex = False\n",
    "                    )   \n",
    "        \n",
    "        num_channels, num_frames = signal.shape\n",
    "        time_axis = torch.arange(0, num_frames) / target_sample_rate\n",
    "    \n",
    "        spectrogram = spectrogram_transform(signal)\n",
    "        spectrogram = torch.squeeze(spectrogram)\n",
    "        spectrogram_db = amplitude_to_db_transform(spectrogram)\n",
    "    \n",
    "        n_fft_spec = (spectrogram_db.shape[0] - 1) * 2\n",
    "        frequency = (target_sample_rate / n_fft_spec) * np.linspace(0, n_fft_spec/2, spectrogram_db.shape[0])\n",
    "    \n",
    "        ax = fig.add_subplot(n_rows, n_cols, index+1)\n",
    "        ax.imshow(spectrogram_db, extent=[0, target_length, 0, target_sample_rate/2], origin=\"lower\", aspect=\"auto\")\n",
    "        ax.set_title(f\"window_fn : {window_name}\", fontweight=\"bold\", fontsize=12)\n",
    "        ax.set_ylabel(\"Frequency (Hz)\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        \n",
    "        \n",
    "fig.suptitle(f\"Spectrogram - {event_name} - Class : {event_class}\", fontsize=20, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "figure_name = f\"Analyse des Features - Spectrogramme - Sensibilité au Paramètre window_fn - {event_name} - {event_class}.png\"\n",
    "plt.savefig(os.path.join(figures_path, figure_name), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed9b1d",
   "metadata": {},
   "source": [
    "## Mel-Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbf499",
   "metadata": {},
   "source": [
    "### Number of Mel Filterbanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1b216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_to_db_transform = torchaudio.transforms.AmplitudeToDB(\n",
    "                    # Scale of input tensor (\"power\" or \"magnitude\"). The power being the elementwise square of the magnitude. (Default: \"power\")\n",
    "                    stype = \"power\",\n",
    "                    # Minimum negative cut-off in decibels. A reasonable number is 80. (Default: None)\n",
    "                    top_db = None\n",
    "                    )\n",
    "\n",
    "n_mels_values = [16, 32, 64, 128]\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(n_fft_values)/n_cols)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for index, n_mels_value in enumerate(n_mels_values):\n",
    "    \n",
    "        mel_spectrogram_transform = torchaudio.transforms.MelSpectrogram( \n",
    "                    # Sample rate of audio signal. (Default: 16000)\n",
    "                    sample_rate = target_sample_rate,\n",
    "                    # Size of FFT, creates n_fft // 2 + 1 bins. (Default: 400)\n",
    "                    n_fft = n_fft_value,\n",
    "                    # Window size. (Default: n_fft)\n",
    "                    win_length = n_fft_value,\n",
    "                    # Length of hop between STFT windows. (Default: win_length // 2)\n",
    "                    hop_length = n_fft_value // 2,\n",
    "                    # Minimum frequency. (Default: 0.)\n",
    "                    f_min = 0,\n",
    "                    # Maximum frequency. (Default: None)\n",
    "                    f_max = None,\n",
    "                    # Two sided padding of signal. (Default: 0)\n",
    "                    pad = 0,\n",
    "                    # Number of mel filterbanks. (Default: 128)\n",
    "                    n_mels = n_mels_value,\n",
    "                    # A function to create a window tensor that is applied/multiplied to each frame/window. (Default: torch.hann_window)\n",
    "                    window_fn = torch.hann_window,\n",
    "                    # Exponent for the magnitude spectrogram, (must be > 0) e.g., 1 for energy, 2 for power, etc. (Default: 2)\n",
    "                    power = 2,\n",
    "                    # Whether to normalize by magnitude after stft. (Default: False)\n",
    "                    normalized = True,\n",
    "                    # Arguments for window function. (Default: None)\n",
    "                    wkwargs = None,\n",
    "                    # whether to pad waveform on both sides so that the tt-th frame is centered at time t \\times \\text{hop\\_length}t×hop_length. (Default: True)\n",
    "                    center = True,\n",
    "                    # Controls the padding method used when center is True. (Default: \"reflect\")\n",
    "                    pad_mode = \"reflect\",\n",
    "                    # Controls whether to return half of results to avoid redundancy. (Default: True)\n",
    "                    onesided = True,\n",
    "                    # If ‘slaney’, divide the triangular mel weights by the width of the mel band (area normalization). (Default: None)\n",
    "                    norm = None,\n",
    "                    # Scale to use: htk or slaney. (Default: \"htk\")\n",
    "                    mel_scale = \"htk\"\n",
    "        )   \n",
    "        \n",
    "        num_channels, num_frames = signal.shape\n",
    "        time_axis = torch.arange(0, num_frames) / target_sample_rate\n",
    "    \n",
    "        mel_spectrogram = mel_spectrogram_transform(signal)\n",
    "        mel_spectrogram = torch.squeeze(mel_spectrogram)\n",
    "        mel_spectrogram_db = amplitude_to_db_transform(mel_spectrogram)\n",
    "    \n",
    "        ax = fig.add_subplot(n_rows, n_cols, index+1)\n",
    "        ax.imshow(mel_spectrogram_db, extent=[0, target_length, 0, n_mels_value], origin=\"lower\", aspect=\"auto\")\n",
    "        ax.set_title(f\"n_mels = {n_mels_value}\", fontweight=\"bold\", fontsize=12)\n",
    "        ax.set_ylabel(\"Mel Bands\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        \n",
    "        \n",
    "fig.suptitle(f\"Mel-Spectrogram - {event_name} - Class : {event_class}\", fontsize=20, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "figure_name = f\"Analyse des Features - Mel-Spectrogramme - Sensibilité au Paramètre n_mels - {event_name} - {event_class}.png\"\n",
    "plt.savefig(os.path.join(figures_path, figure_name), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3010867",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a40d05",
   "metadata": {},
   "source": [
    "### Number of Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc_values = [20, 40, 60, 80]\n",
    "\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(n_fft_values)/n_cols)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for index, n_mfcc_value in enumerate(n_mfcc_values):\n",
    "    \n",
    "        mfcc_transform = torchaudio.transforms.MFCC( \n",
    "                    # Sample rate of audio signal. (Default: 16000)\n",
    "                    sample_rate = target_sample_rate,\n",
    "                    # Number of mfc coefficients to retain. (Default: 40)\n",
    "                    n_mfcc = n_mfcc_value,\n",
    "                    # Type of DCT (discrete cosine transform) to use. (Default: 2)\n",
    "                    dct_type = 2,\n",
    "                    # Norm to use. (Default: \"ortho\")\n",
    "                    norm = \"ortho\",\n",
    "                    # Whether to use log-mel spectrograms instead of db-scaled. (Default: False)\n",
    "                    log_mels = False,\n",
    "                    # Arguments for MelSpectrogram. (Default: None)\n",
    "                    melkwargs = None\n",
    "        )   \n",
    "        \n",
    "        num_channels, num_frames = signal.shape\n",
    "        time_axis = torch.arange(0, num_frames) / target_sample_rate\n",
    "    \n",
    "        mfcc = mfcc_transform(signal)\n",
    "        mfcc = torch.squeeze(mfcc)\n",
    "    \n",
    "        ax = fig.add_subplot(n_rows, n_cols, index+1)\n",
    "        ax.imshow(mfcc, extent=[0, target_length, 0, n_mfcc_value], origin=\"lower\", aspect=\"auto\")\n",
    "        ax.set_title(f\"n_mfcc = {n_mfcc_value}\", fontweight=\"bold\", fontsize=12)\n",
    "        ax.set_ylabel(\"MFCC\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "        \n",
    "        \n",
    "fig.suptitle(f\"MFCC - {event_name} - Class : {event_class}\", fontsize=20, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "figure_name = f\"Analyse des Features - MFCC - Sensibilité au Paramètre n_mfcc - {event_name} - {event_class}.png\"\n",
    "plt.savefig(os.path.join(figures_path, figure_name), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UrbanSound8K",
   "language": "python",
   "name": "urbansound8k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
